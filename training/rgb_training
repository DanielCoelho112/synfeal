#!/usr/bin/env python3
import torch
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
import argparse
import sys
import os
from tqdm import tqdm
import yaml
import pickle

from colorama import Fore, Style
from datetime import datetime  # to track the time each epoch takes
from torchvision import transforms

from dataset import Dataset
from visualization import Visualizer
from models.loss_functions import BetaLoss, DynamicLoss
from models.posenet import PoseNetGoogleNet, PoseNetResNet
from models.poselstm import PoseLSTM
from models.hourglass import HourglassBatch
from utils import summarizeModel, resumeTraining, process_pose

def main():
    parser = argparse.ArgumentParser(description='PointNet training')
    parser.add_argument('-v', '--visualize', action='store_true')
    parser.add_argument('-c', '--cuda', action='store_true')
    parser.add_argument('-gpu', '--gpu', type=int, default=0)
    parser.add_argument('-sm', '--summarize_model', action='store_true')
    parser.add_argument('-fn', '--folder_name', type=str, required=True, help='folder name')
    parser.add_argument('-mn', '--model_name', type=str, required=True, help='model name')
    parser.add_argument('-train_set', '--training_set', type=str, required=True, help='Name of the training set')
    parser.add_argument('-test_set', '--testing_set', type=str, required=True, help='Name of the testing set')
    parser.add_argument('-n_epochs', '--n_epochs', type=int, required=True, help='Number of epochs')
    parser.add_argument('-ss', '--save_step', type=int, default=10, help='Each X epochs, the parameters of the model are save')
    parser.add_argument('-batch_size', '--batch_size', type=int, required=True, help='Batch size')
    parser.add_argument('-loss', '--loss_function', type=str, default='DynamicLoss()',
                        help='Type of loss function. [DynamicLoss(), BetaLoss(B)]')
    parser.add_argument('-lr', '--learning_rate', type=float, default=1e-4, help='Learning rate value')
    parser.add_argument('-lr_step_size', '--lr_step_size', type=int, default=20,
                        help='Step size of the learning rate decay')
    parser.add_argument('-lr_gamma', '--lr_gamma', type=float, default=0.5,
                        help='Decay of the learning rate after step size')
    parser.add_argument('-wd', '--weight_decay', type=float, default=0, help='L2 regularizer')
    parser.add_argument('-im', '--init_model', type=str, default='CNNDepth()',
                        help='Initial model choose between [PoseNetGoogleNet(), PoseNetResNet(), PoseLSTM(), HourglassBatch()]')
    parser.add_argument('-cs', '--crop_size', type=int, default=299,
                        help='Size of the random and center crop. For PoseNet/LSTM use 299, for Hourglass use 224')
    parser.add_argument('-augm', '--augmentation', action='store_true', 
                        help='Performs Data Augmentation on the dataset')
    parser.add_argument('-nw', '--num_workers', type=int, default=4, 
                        help='How many subprocesses to use for data loading. 0 means that the data will be loaded in the main process.')
    parser.add_argument('-pff', '--prefetch_factor', type=int, default=2, 
                        help='Number of batches loaded in advance by each worker')

    arglist = [x for x in sys.argv[1:] if not x.startswith('__')]
    args = vars(parser.parse_args(args=arglist))

    if args['cuda']:
        if not torch.cuda.is_available():
            raise ValueError('Cuda is not available.')
        else:
            print(f'{Fore.GREEN} Cuda is available {Fore.RESET}')
            torch.cuda.set_device(args['gpu'])

    path=os.environ.get("HOME")
    folder_name = f'{path}/models/synfeal/{args["folder_name"]}'
    model_name = f'{folder_name}/{args["model_name"]}.pth'
    
    config_stats = Dataset(path_seq=args['training_set']).getConfig()['statistics']
    rgb_mean = [config_stats['R']['mean'], config_stats['G']['mean'], config_stats['B']['mean']]
    rgb_std = [config_stats['R']['std'], config_stats['G']['std'], config_stats['B']['std']]

    # rgb_mean = [0.485, 0.456, 0.406]
    # rgb_std = [0.229, 0.224, 0.225]
    if args['augmentation']:    
        rgb_transform_train = transforms.Compose([
            transforms.Resize(args['crop_size'] + 1),
            transforms.RandomCrop(args['crop_size']),
            transforms.ToTensor(),
            transforms.ColorJitter(brightness=[0.5,2], hue=0),
            transforms.RandomErasing(),
            transforms.Normalize(rgb_mean, rgb_std),
        ])
    else:
        rgb_transform_train = transforms.Compose([
            transforms.Resize(args['crop_size'] + 1),
            transforms.CenterCrop(args['crop_size']),
            transforms.ToTensor(),
            transforms.Normalize(rgb_mean, rgb_std)
        ])
    
    rgb_transform_test = transforms.Compose([
        transforms.Resize(args['crop_size'] + 1),
        transforms.CenterCrop(args['crop_size']),
        transforms.ToTensor(),
        transforms.Normalize(rgb_mean, rgb_std)
    ])
    
    print(f'rgb_transform_test is: {rgb_transform_test.transforms}')
    
    train_dataset = Dataset(path_seq=args['training_set'], rgb_transform = rgb_transform_train, depth_transform = None, inputs=['rgb_image'])
    test_dataset = Dataset(path_seq=args['testing_set'], rgb_transform = rgb_transform_test, depth_transform = None, inputs=['rgb_image'])

    # check if the datasets are validated
    config_train = train_dataset.getConfig()
    config_test = test_dataset.getConfig()
    if not config_train['is_valid']:
        print(f'{Fore.RED} {train_dataset.seq} is not valid!')
        exit(0)
    if not config_test['is_valid']:
        print(f'{Fore.RED} {test_dataset.seq} is not valid!')
        exit(0)

    batch_size = args['batch_size']
    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False , num_workers=args['num_workers'])
    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False , num_workers=args['num_workers'])

    # start training, resume training, or abandon training?
    if os.path.exists(folder_name):
        print(Fore.YELLOW + f'Folder already exists! Do you want to resume training?' + Style.RESET_ALL)
        ans = input(Fore.YELLOW + "Y" + Style.RESET_ALL + "ES/" + Fore.YELLOW + "n" + Style.RESET_ALL + "o/"+ Fore.YELLOW + "o" + Style.RESET_ALL + "verwrite: ") # Asks the user if they want to resume training
        
        if ans.lower() in ['', 'yes','y']:
            try:
                torch.load(model_name)
            except FileNotFoundError:
                print(Fore.YELLOW + 'Folder empty' + Style.RESET_ALL)
                ans = 'o'
            else:
                start_epoch, train_losses, test_losses, model = resumeTraining(folder_name)
        if ans.lower() in ['overwrite', 'o']:
            print(Fore.YELLOW + 'Overwriting.' + Style.RESET_ALL)
            os.system('rm -rf ' + folder_name)
        if ans.lower() not in ['', 'yes', 'y', 'overwrite', 'o']: # If the user does not want to resume training
            print(f'{Fore.RED} Terminating training... {Fore.RESET}')
            exit(0)
    if not os.path.exists(folder_name) or ans.lower() in ['overwrite', 'o']: # If the model does not exist
        print(f'Model Folder not found: {folder_name}. {Fore.YELLOW} Starting from sratch.{Style.RESET_ALL}')
        os.makedirs(folder_name)
        model = eval(args['init_model'])
        train_losses = []
        test_losses = []
        start_epoch = 0
        
    # convert transforms to pickle files
    with open(f'{folder_name}/rgb_transform_train.pickle', 'wb') as handle:
        pickle.dump(rgb_transform_train, handle, protocol=pickle.HIGHEST_PROTOCOL)
    with open(f'{folder_name}/rgb_transform_test.pickle', 'wb') as handle:
        pickle.dump(rgb_transform_test, handle, protocol=pickle.HIGHEST_PROTOCOL)
    
    
    if args['summarize_model']:
        summarizeModel(model, (args['batch_size'],3, args['crop_size'], args['crop_size']))
        
    # ----------------------------------
    # Define loss function
    # ----------------------------------
    criterion = eval(args['loss_function'])
    
    # Add all params for optimization
    param_list = [{'params': model.parameters()}]
    if isinstance(criterion, DynamicLoss):
        # Add sx and sq from loss function to optimizer params
        param_list.append({'params': criterion.parameters()})

    optimizer = optim.Adam(params = param_list, lr=args['learning_rate'], weight_decay=args['weight_decay']) # the most common optimizer in DL
    # weight decay is the L2 regularizer!!

    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args['lr_step_size'], gamma=args['lr_gamma'])

    # ----------------------------------
    # Training
    # ----------------------------------
    stored_test_loss_epoch = np.inf
    
    n_epochs = args['n_epochs']

    first_time = True
    save_step = args['save_step'] # when to store the model
    last_saved_epoch = 0

    if args['cuda']:
        model.cuda()  # Send model to GPU
        criterion.cuda()  # Send criterion to GPU
        
    for epoch in range(start_epoch, n_epochs+1):
        t0 = datetime.now()
        train_losses_per_batch = []
        model.train()
        for (rgb_image, target_pose) in tqdm(train_loader, total=len(train_loader), desc=Fore.GREEN + 'Training batches for Epoch ' + str(epoch) +  Style.RESET_ALL):  # iterate batches
            
            if args['cuda']:
                rgb_image, target_pose = rgb_image.cuda(), target_pose.cuda()  # move data into GP

            #model = model.train()  # Sets the module in training mode. For example, the dropout module can only be use in training mode.

            if model.aux_logits:
            
                pose_aux1, pose_aux2, pose = model(rgb_image)  # our model outputs the pose, and the transformations used
                
                pose_aux1  = process_pose(pose_aux1)
                pose_aux2  = process_pose(pose_aux2)
                pose = process_pose(pose)
                
                loss_aux1 = criterion(pose_aux1, target_pose)
                loss_aux2 = criterion(pose_aux2, target_pose)
                loss_pose = criterion(pose, target_pose)
                
                loss = loss_pose + 0.3 * (loss_aux1 + loss_aux2) # https://arxiv.org/abs/1409.4842
            
            else:
                pose = model(rgb_image)
                pose = process_pose(pose)
                loss = criterion(pose, target_pose)
            optimizer.zero_grad()  # Clears the gradients of all optimized tensors (always needed in the beginning of the training loop)
            loss.backward()  # Computes the gradient of current tensor w.r.t. graph leaves.
            optimizer.step()  # Performs a single optimization step (parameter update).

            train_losses_per_batch.append(loss.item())

        train_loss_epoch = float(np.mean(train_losses_per_batch))

        test_losses_per_batch = []
        model.eval()
        for (rgb_image, target_pose) in tqdm(test_loader, total=len(test_loader), desc=Fore.GREEN + 'Testing batches for Epoch ' + str(epoch) +  Style.RESET_ALL):
            if args['cuda']:
                rgb_image, target_pose = rgb_image.cuda(), target_pose.cuda()  # move data into GPU

            #model = model.eval()  # Sets the module in evaluation mode.

            predicted_pose = model(rgb_image)  # our model outputs the pose, and the transformations used
            predicted_pose = process_pose(predicted_pose)

            loss = criterion(predicted_pose, target_pose)

            test_losses_per_batch.append(loss.item())

            if first_time: # Checks if the user wants to visualize the loss
                test_visualizer = Visualizer('Test Images')
            if args['visualize']:
                test_visualizer.draw(rgb_image, target_pose, predicted_pose)

        test_loss_epoch = float(np.mean(test_losses_per_batch))

        # save losses
        train_losses.append(train_loss_epoch)
        test_losses.append(test_loss_epoch)
        
        dt = datetime.now() - t0
        print(
            f'epoch {epoch}/{n_epochs}, train_loss: {train_loss_epoch:.4f}, test_loss: {test_loss_epoch:.4f}, duration: {dt}')
        
        
        scheduler.step()

        # ----------------------
        # Visualization
        # ----------------------
        if args['visualize']:
            plt.figure('Losses')
            if first_time:
                hanle_train_plot = plt.plot(train_losses, label='train loss')
                hanle_test_plot = plt.plot(test_losses, label='test loss')
                first_time = False
                plt.legend()
            else:
                hanle_train_plot[0].set_data(range(0,len(train_losses)), train_losses)
                hanle_test_plot[0].set_data(range(0,len(test_losses)), test_losses)
                axis = plt.gca()
                axis.relim(), axis.autoscale_view() # resize axis

            plt.draw()
            plt.waitforbuttonpress(0.01)
                   
        # ------------------
        # Saving of Model
        # ------------------
        if (epoch)%save_step == 0:            
            # only save if test loss is lower than the previous saved!
            if test_loss_epoch < stored_test_loss_epoch:
                last_saved_epoch = epoch
                # todo: in addition to save the state_dict of the model, we should also save the state_dict of the optimizer.
                torch.save(model.state_dict(), model_name)
            
                dt_now = datetime.now()  # current date and time
                config = {'user': os.environ["USER"],
                        'date': dt_now.strftime("%d/%m/%Y, %H:%M:%S"),
                        'train_set': args['training_set'],
                        'test_set': args['testing_set'],
                        'Augmentation' : args['augmentation'],
                        'max_n_epochs': args['n_epochs'],
                        'epoch': epoch+1,
                        'batch_size': args['batch_size'],
                        'loss': args['loss_function'],
                        'learning_rate': args['learning_rate'],
                        'lr_step_size': args['lr_step_size'],
                        'lr_gamma': args['lr_gamma'],
                        'init_model': args['init_model'],
                        'train_losses': train_losses,
                        'test_losses': test_losses,
                        'weight_decay' : args['weight_decay']}

                with open(f'{folder_name}/config.yaml', 'w') as file:
                    yaml.dump(config, file)

                print(f'Saved model at epoch {epoch}')
                stored_test_loss_epoch = test_loss_epoch
            else:
                print('Current model is no better than the stored model. Ignoring saving.')
        
            plt.figure()
            plt.plot(train_losses, label='train loss')
            plt.plot(test_losses, label='test loss')
            plt.axvline(x = last_saved_epoch, color = 'b', label = 'last saved epoch')
            plt.xlabel("Epoch")    
            plt.ylabel("Loss")   
            #plt.xticks(np.arange(0, n_epochs, 1.0)
            plt.legend()
            plt.savefig(f'{folder_name}/losses.png')
            

if __name__ == "__main__":
    main()
